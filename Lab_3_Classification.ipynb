{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASMT-College/lab-3-classification-rahulkarki312/blob/main/Lab_3_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to predict whether a patient has diabetes based on certain health attributes using two classification algorithms:\n",
        "\n",
        "**Naive Bayes** and\n",
        "\n",
        "**ID3 Decision Tree**.\n",
        "\n",
        "After building both models, we'll compare their performance using metrics like accuracy, precision, recall, and F1-score.\n",
        "\n",
        "**Dataset: diabetes_data.csv**\n",
        "\n",
        "You can use the Pima Indians Diabetes dataset, which contains the following attributes:\n",
        "\n",
        "**Pregnancies:** Number of times pregnant\n",
        "\n",
        "**Glucose:** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure:** Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness:** Triceps skinfold thickness (mm)\n",
        "\n",
        "**Insulin:** 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI:** Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction:** Diabetes pedigree function\n",
        "\n",
        "**Age:** Age (years)\n",
        "\n",
        "**Outcome: Class variable (0 or 1)**, where 1 means the patient has diabetes and 0 means they don't.\n"
      ],
      "metadata": {
        "id": "Ans1G1dqxc7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Predict Diabetes using Naive Bayes Classification"
      ],
      "metadata": {
        "id": "Vvpzocz1x9Hl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtN4gU6ovaGi",
        "outputId": "769e7781-3b8d-41a0-d5f2-0e4022c9b10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.74\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.80       151\n",
            "           1       0.62      0.66      0.64        80\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.72      0.73      0.72       231\n",
            "weighted avg       0.75      0.74      0.75       231\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Pregnancies': [6, 1, 8, 1, 0, 5, 3, 10, 2, 8],\n",
        "    'Glucose': [148, 85, 183, 89, 137, 116, 78, 115, 197, 125],\n",
        "    'BloodPressure': [72, 66, 64, 66, 40, 74, 50, 0, 70, 96],\n",
        "    'SkinThickness': [35, 29, 0, 23, 35, 0, 32, 0, 45, 0],\n",
        "    'Insulin': [0, 0, 0, 94, 168, 0, 88, 0, 543, 0],\n",
        "    'BMI': [33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.3, 30.5, 30.0],\n",
        "    'DiabetesPedigreeFunction': [0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.248, 0.134, 0.158, 0.232],\n",
        "    'Age': [50, 31, 32, 21, 33, 30, 26, 29, 53, 54],\n",
        "    'Outcome': [1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
        "}\n",
        "\n",
        "# Load the dataset\n",
        "# df = pd.DataFrame(data)\n",
        "df = pd.read_csv('lab3-datasets/diabetes.csv')\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df.drop(columns='Outcome')\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_nb = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(f\"Naive Bayes Accuracy: {accuracy_nb:.2f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Predict Diabetes using ID3 Decision Tree Classifier"
      ],
      "metadata": {
        "id": "azFtb2EKyF46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Sample dataset (same as above)\n",
        "data = {\n",
        "    'Pregnancies': [6, 1, 8, 1, 0, 5, 3, 10, 2, 8],\n",
        "    'Glucose': [148, 85, 183, 89, 137, 116, 78, 115, 197, 125],\n",
        "    'BloodPressure': [72, 66, 64, 66, 40, 74, 50, 0, 70, 96],\n",
        "    'SkinThickness': [35, 29, 0, 23, 35, 0, 32, 0, 45, 0],\n",
        "    'Insulin': [0, 0, 0, 94, 168, 0, 88, 0, 543, 0],\n",
        "    'BMI': [33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.3, 30.5, 30.0],\n",
        "    'DiabetesPedigreeFunction': [0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.248, 0.134, 0.158, 0.232],\n",
        "    'Age': [50, 31, 32, 21, 33, 30, 26, 29, 53, 54],\n",
        "    'Outcome': [1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
        "}\n",
        "\n",
        "# Load the dataset\n",
        "# df = pd.DataFrame(data)\n",
        "df = pd.read_csv('lab3-datasets/diabetes.csv')\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df.drop(columns='Outcome')\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt:.2f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjD7wC6gyKmE",
        "outputId": "c970ad32-7550-411f-d70b-f516d3a54d94"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.73\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79       151\n",
            "           1       0.60      0.62      0.61        80\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.70      0.70      0.70       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Compare Performance of Both Classifiers"
      ],
      "metadata": {
        "id": "TcZNzTH2yOH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "# Calculate confusion matrices\n",
        "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "# Calculate ROC AUC scores\n",
        "roc_auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
        "roc_auc_dt = roc_auc_score(y_test, y_pred_dt)\n",
        "\n",
        "# Print comparison resultsprint(\"\\nNaive Bayes vs Decision Tree Classifier Performance:\\n\")\n",
        "print(f\"Naive Bayes Accuracy: {accuracy_nb:.2f}\")\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt:.2f}\")\n",
        "print(f\"Naive Bayes ROC AUC: {roc_auc_nb:.2f}\")\n",
        "print(f\"Decision Tree ROC AUC: {roc_auc_dt:.2f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix - Naive Bayes:\\n\", conf_matrix_nb)\n",
        "print(\"\\nConfusion Matrix - Decision Tree:\\n\", conf_matrix_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4kyE6vpyTYr",
        "outputId": "9d498140-02e9-4e42-e529-b0321dad5297"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.74\n",
            "Decision Tree Accuracy: 0.73\n",
            "Naive Bayes ROC AUC: 0.73\n",
            "Decision Tree ROC AUC: 0.70\n",
            "\n",
            "Confusion Matrix - Naive Bayes:\n",
            " [[119  32]\n",
            " [ 27  53]]\n",
            "\n",
            "Confusion Matrix - Decision Tree:\n",
            " [[118  33]\n",
            " [ 30  50]]\n"
          ]
        }
      ]
    }
  ]
}